{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MOwNiT lab5 - iteracyjne metody rozwiązywania równań liniowych"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Przydatne linki: </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- CPP: https://en.cppreference.com/w/\n",
    "\n",
    "- Metoda Jacobiego: https://en.wikipedia.org/wiki/Jacobi_method\n",
    "- Metoda SOR: https://en.wikipedia.org/wiki/Successive_over-relaxation\n",
    "- Metoda Gaussa-Seidela: https://en.wikipedia.org/wiki/Gauss%E2%80%93Seidel_method\n",
    "- Rozserzona wersja wstępu teoretycznego : http://mst.mimuw.edu.pl/lecture.php?lecture=mo2&part=Ch5#E12\n",
    "\n",
    "\n",
    "\n",
    "**Dodatkowe źródła**\n",
    "- Bardzo przydatne praktyczne przykłady z opracowaniem wszystkich bardziej znanych metod (od str. 107) : http://bc.pollub.pl/Content/1370/metody.pdf\n",
    "- Kincaid, Cheney, rozdz. 8.2, str. 319"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Wstęp teoretyczny</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rozważać będziemy metody iteracyjne, które mogą posłużyć do rozwiązania prostego układu równań: $Ax = b$, $A$ - macierz nieosobliwa (zapewne wielkiego) rozmiaru . Są to metody najprostsze w analizie i implementacji, ale najmniej efektywne. Stanowią jednak ważny składnik jednej z najszybszych metod rozwiązywania niektórych trudnych układów równań.\n",
    "\n",
    "Metody iteracyjne przedstawione na zajęciach bazują na idei rozkładu macierzy $A$ na część ,,łatwo odwracalną” $M$ oraz ,,resztę” $Z$ ($Z = M - A$) .\n",
    "\n",
    "Wszystkie będą bazować na podziale macierzy $A$ na trzy części: diagonalną $D$, ściśle dolną trójkątną $L$ i ściśle górną trójkątną $U$:\n",
    "\n",
    "$L=\\begin{pmatrix}0&&&&\\\\\n",
    "a_{{21}}&0&&&\\\\\n",
    "a_{{31}}&a_{{32}}&0&&\\\\\n",
    "\\vdots&\\vdots&\\ddots&0&\\\\\n",
    "a_{{N1}}&a_{{N2}}&\\cdots&\\cdots&0\\end{pmatrix},\\quad D=\\begin{pmatrix}a_{{11}}&&&&\\\\\n",
    "&a_{{22}}&&&\\\\\n",
    "&&\\ddots&&\\\\\n",
    "&&&\\ddots&\\\\\n",
    "&&&&a_{{NN}}\\end{pmatrix},\\quad U=\\begin{pmatrix}0&a_{{12}}&a_{{13}}&\\cdots&a_{{1N}}\\\\\n",
    "&0&a_{{23}}&\\cdots&a_{{2N}}\\\\\n",
    "&&0&\\ddots&\\vdots\\\\\n",
    "&&&0&\\vdots\\\\\n",
    "&&&&0\\end{pmatrix}$\n",
    "\n",
    "<h3> Metoda Jacobiego </h3>\n",
    "\n",
    "Możemy jej użyć pod warunkiem, że macierz jest dominująca:  $ |a_{ii}|\\geq \\sum _{j\\neq i}|a_{ij}| \\hspace{2mm} \\forall \\hspace{2mm} i. $\n",
    "\n",
    "Zapis macierzowy kroku iteracji wygląda następująco: \n",
    "\n",
    "$$x_{{k+1}}\\,=D^{{-1}}(b-(L+U)x_{{k}})$$\n",
    "\n",
    "Po rozpisaniu na kolejne współrzędne otrzymujemy układ rozszczepionych równań (numer iteracji wyjątkowo zaznaczamy w postaci górnego indeksu):\n",
    "\n",
    "$$x^{{(k+1)}}_{i}=\\frac{1}{a_{{ii}}}\\left(b_{i}-\\sum _{{j\\neq i}}a_{{ij}}x^{{(k)}}_{j}\\right)$$\n",
    "\n",
    "(!) Ważny do zapamiętania jest fakt, że jesteśmy w stanie bardzo łatwo odwrócić macierz.\n",
    "\n",
    "\n",
    "**Zadanie 1**\n",
    "Proszę zaimplementować metodę Jacobiego oraz przetestować jej działanie na kilku znalezionych przez siebie układach równań (nie mniej niż 5 układów, nie więcej niż 10, w miarę możliwości różnorodne). Układy podać w sprawozdaniu.\n",
    "\n",
    "<h3> Metoda Gaussa-Seidela </h3>\n",
    "\n",
    "Heurystyka tej metody opiera się na zmodyfikowaniu metody Jacobiego tak, by w każdym momencie iteracji korzystać z najbardziej ,,aktualnych” współrzędnych przybliżenia rozwiązania $x$ (inny rozkład macierzy $A$).\n",
    "\n",
    "Zapis macierzowy kroku iteracji wygląda następująco: \n",
    "\n",
    "$$x_{{k+1}}=(L+D)^{{-1}}(b-Ux_{{k}})$$\n",
    "\n",
    "Po rozpisaniu na kolejne współrzędne otrzymujemy:\n",
    "\n",
    "$$x^{{(k+1)}}_{i}=\\frac{1}{a_{{ii}}}\\left(b_{i}-\\sum _{{j<i}}a_{{ij}}x^{{(k+1)}}_{j}-\\sum _{{j>i}}a_{{ij}}x^{{(k)}}_{j}\\right)$$\n",
    "\n",
    "**Zadanie 2**\n",
    "Proszę zaimplementować metodę Gaussa-Seidela oraz przetestować jej działanie na układach równań z poprzedniego zadania.\n",
    "\n",
    "<h3> Metoda SOR (Successive Over Relaxation) </h3>\n",
    "\n",
    "Zbieżność metody Gaussa–Seidela można przyspieszyć, wprowadzając parametr relaksacji $\\omega$ i kolejne współrzędne nowego przybliżenia wyznaczać poprzez kombinacje poprzedniego przybliżenia $x^{{(k)}}_{i}$ oraz współrzędną nowego przybliżenia $\\tilde{x}^{{k+1}}_{i}$. Nowe przybliżenie uzyskujemy za pomocą metody Gaussa–Seidela:\n",
    "\n",
    "$x^{{(k+1)}}_{i}=(1-\\omega)x^{{(k)}}_{i}+\\omega\\tilde{x}^{{k+1}}_{i}$\n",
    "\n",
    "Gdy $\\omega=1$ => metoda Gaussa–Seidela.\n",
    "\n",
    "Ostatecznie po podstawieniu otrzymujemy: \n",
    "\n",
    "$$ x_{i}^{(k+1)}=(1-\\omega )x_{i}^{(k)}+{\\frac {\\omega }{a_{ii}}}\\left(b_{i}-\\sum _{j\\lt i}a_{ij}x_{j}^{(k+1)}-\\sum _{j\\gt i}a_{ij}x_{j}^{(k)}\\right),\\quad i=1,2,\\ldots ,n. $$\n",
    "\n",
    "Rozkład macierzy dla metody SOR z parametrem $\\omega$ jest zadany przez: \n",
    "\n",
    "$$M=\\frac{1}{\\omega}D+L,\\qquad Z=\\left(\\frac{1}{\\omega}-1\\right)D-U$$\n",
    "\n",
    "**Zadanie 3**\n",
    "Proszę zaimplementować metodę SOR oraz przetestować jej działanie na układach równań z poprzedniego zadania.\n",
    "\n",
    "**Zadanie 4**\n",
    "Proszę o **TEORETYCZNE** porównanie powyższych metod (zasadniczo wystarczy przeczytać ze zrozumienie wstęp teoretyczny i własnymi słowami je porównać). Proszę wziąć pod uwagę aspekt zbieżności oraz rozkładu na składowe macierze.  \n",
    "\n",
    "**Zadanie 5**\n",
    "Proszę dla powyższych metod porównać tempo zbiegania do rozwiązania (na wykresie). Co można zaobserwować i o czym to może świadczyć?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**zad 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "typedef std::vector<std::vector<double>> arr2d;\n",
    "typedef std::vector<double> arr1d;\n",
    "arr1d Jacobi_solve(arr2d &A, arr1d &B, int k){\n",
    "\n",
    "    int n = A.size();\n",
    "\n",
    "    arr1d X1(n, 0);\n",
    "    arr1d X2(n, 0);\n",
    "\n",
    "    for(int i = 0; i < k; i++){\n",
    "        for(int j = 0; j < n; j++){\n",
    "            double sum = 0;\n",
    "            for(int s = 0; s < n; s++){\n",
    "                if( s != j){\n",
    "                    sum += A[j][s]*X1[s];\n",
    "                }\n",
    "            }\n",
    "\n",
    "            X2[j] = (1.0/A[j][j])*(B[j] - sum); \n",
    "        }\n",
    "        for(int j = 0; j < n; j++){\n",
    "            X1[j] = X2[j];\n",
    "        }\n",
    "    }\n",
    "\n",
    "    std::cout << \" A: \" << std::endl;\n",
    "    print_matrix(A);\n",
    "    std::cout << \" X2: \" << std::endl;\n",
    "    print_matrix1d(X2);\n",
    "\n",
    "\n",
    "    return X2;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "void run_tests(arr1d (*test_func)(arr2d &A, arr1d &B, int k), int iter){\n",
    "    arr2d A1({{5 ,2 ,1 ,1}, {2 ,6 ,2 ,1}, {1, 2, 7, 1}, {1, 1, 2, 8}});\n",
    "    arr2d A2({{2,1}, {5,7}});\n",
    "    arr2d A3({{3.23,2.22,1.11}, {3.34, 4.78, -1.2}, {-1, -1, 1.96}});\n",
    "    arr2d A4({{333, 90, -20}, {70,120,40}, {20,40,85}});\n",
    "    arr2d A5({{45, 12, 1, 6, 10},\n",
    "              {7, 34, 0, 2, 6},\n",
    "               {6, 3, 62, 2 ,1},\n",
    "               {5, 4, 1, 34, 3},\n",
    "               {15, 13, 8, 9, 53}});\n",
    "\n",
    "    arr2d A6({{29, 2, 12, 7},\n",
    "              {17, 54, 18, 21},\n",
    "              {7, 9, 39, 9},\n",
    "              {2, 4, 1, 19}});\n",
    "\n",
    "    arr1d B1({29, 31, 26, 19});\n",
    "    arr1d B2({11,13});\n",
    "    arr1d B3({7,14,2});\n",
    "    arr1d B4({90,70,80});\n",
    "    arr1d B5({33, 17, 5 ,1, 22});\n",
    "    arr1d B6({1, 22, 1, 0});\n",
    "\n",
    "    arr1d X;\n",
    "    arr1d Xn;\n",
    "\n",
    "    std::cout << \"1. blad: \";\n",
    "    X = test_func(A1, B1, iter);\n",
    "    Xn = solve_normally(A1, B1);\n",
    "    std::cout << calc_error_sum(X, Xn) << std::endl;\n",
    "\n",
    "    std::cout << \"2. blad: \";\n",
    "    X = test_func(A2, B2, iter);\n",
    "    Xn = solve_normally(A2, B2);\n",
    "    std::cout << calc_error_sum(X, Xn) << std::endl;\n",
    "    \n",
    "    std::cout << \"3. blad: \";\n",
    "    X = test_func(A3, B3, iter);\n",
    "    Xn = solve_normally(A3, B3);\n",
    "    std::cout << calc_error_sum(X, Xn) << std::endl;\n",
    "     \n",
    "    std::cout << \"4. blad: \";\n",
    "    X = test_func(A4, B4, iter);\n",
    "    Xn = solve_normally(A4, B4);\n",
    "    std::cout << calc_error_sum(X, Xn) << std::endl;\n",
    "    \n",
    "    std::cout << \"5. blad: \";\n",
    "    X = test_func(A5, B5, iter);\n",
    "    Xn = solve_normally(A5, B5);\n",
    "    std::cout << calc_error_sum(X, Xn) << std::endl;\n",
    "    \n",
    "    std::cout << \"6. blad: \";\n",
    "    X = test_func(A6, B6, iter);\n",
    "    Xn = solve_normally(A6, B6);\n",
    "    std::cout << calc_error_sum(X, Xn) << std::endl;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_tests(Jacobi_solve, 10);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "1. blad: 0.237305\n",
    "2. blad: 0.0600413\n",
    "3. blad: 0.299063\n",
    "4. blad: 0.00315262\n",
    "5. blad: 0.0035626\n",
    "6. blad: 0.00403105\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**zad 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr1d Gauss_Seidel_solve(arr2d &A, arr1d &B, int k){\n",
    "\n",
    "    int n = A.size();\n",
    "\n",
    "\n",
    "    arr1d X1(n, 0);\n",
    "    arr1d X2(n, 0);\n",
    "\n",
    "    for(int i = 0; i < k; i++){\n",
    "        for(int j = 0; j < n; j++){\n",
    "            double sum1 = 0;\n",
    "            for(int s = 0; s < j; s++){\n",
    "                sum1 += A[j][s]*X2[s];\n",
    "            }\n",
    "            double sum2 = 0;\n",
    "            for(int s = j+1; s < n; s++){\n",
    "                sum2 += A[j][s]*X1[s];\n",
    "            }\n",
    "            X2[j] = (1.0/A[j][j])*(B[j] - sum1 - sum2); \n",
    "        }\n",
    "        for(int j = 0; j < n; j++){\n",
    "            X1[j] = X2[j];\n",
    "        }\n",
    "    }\n",
    "\n",
    "    return X2;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_tests(Gauss_Seidel_solve, 10);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "1. blad: 5.16447e-08\n",
    "2. blad: 0.000261088\n",
    "3. blad: 0.000181203\n",
    "4. blad: 1.55005e-06\n",
    "5. blad: 6.09929e-10\n",
    "6. blad: 2.6676e-09\n",
    "    \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**zad 3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr1d SOR_solve(arr2d &A, arr1d &B, int k){\n",
    "\n",
    "    int n = A.size();\n",
    "    double w = 0.5;\n",
    "\n",
    "    arr1d X1(n, 0);\n",
    "    arr1d X2(n, 0);\n",
    "\n",
    "    for(int i = 0; i < k; i++){\n",
    "        for(int j = 0; j < n; j++){\n",
    "            double sum1 = 0;\n",
    "            for(int s = 0; s < j; s++){\n",
    "                sum1 += A[j][s]*X2[s];\n",
    "            }\n",
    "            double sum2 = 0;\n",
    "            for(int s = j+1; s < n; s++){\n",
    "                sum2 += A[j][s]*X1[s];\n",
    "            }\n",
    "            X2[j] = (1.0 - w)*X1[j] + (w/A[j][j])*(B[j] - sum1 - sum2); \n",
    "        }\n",
    "        for(int j = 0; j < n; j++){\n",
    "            X1[j] = X2[j];\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "    return X2;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_tests(SOR_solve, 10);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "1. blad: 0.00818885\n",
    "2. blad: 0.620093\n",
    "3. blad: 1.37506\n",
    "4. blad: 0.037829\n",
    "5. blad: 0.00188592\n",
    "6. blad: 0.00693356\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**zad 4**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wszystkie metody iteracyjne korzystają z rozkładu macierzy na $A = D + L + U$\n",
    "\n",
    "W metodzie Jacobiego macierz (L + U) traktujemy jako jedną macierz. Jest to najprostsza z tych trzech metod. W teorii jest również metodą najwolniej zbiegającą.\n",
    "\n",
    "W metodzie Gaussa-Seidela macierz (L + D) traktujemy jako jedną macierz. Jest to ulepszona metoda Jacobiego, ponieważ w każdym kroku iteracji korzysta z wyliczonych wartosći już w tym kroku, a więc nowszych. Dzięki temu metoda ta szybciej zbiega od metody Jacobiego\n",
    "\n",
    "Metoda SOR jest usprawnieniem metody Gaussa-Seidela. Macierz w niej jest również dzielona na części U + (L + D).\n",
    "Ulepszenie polega na dodaniu współczynnika relaksacji, który dobrze dobrany poprawia zbieżność zwiększając, bądź zmniejszając znaczenie dodawanej \"poprawki\" w kolejnych krokach iteracji."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**zad 5**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Macierze A1\n",
    "\n",
    "![](./plot.png)\n",
    "\n",
    "Macierze A2\n",
    "\n",
    "![](./plot2.png)\n",
    "\n",
    "Macierze A3\n",
    "\n",
    "![](./plot3.png)\n",
    "\n",
    "Macierze A4\n",
    "\n",
    "![](./plot4.png)\n",
    "\n",
    "Macierze A5\n",
    "\n",
    "![](./plot5.png)\n",
    "\n",
    "Macierze A6\n",
    "\n",
    "![](./plot6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Widać że najszybciej zbiega metoda Gaussa-Seidela. Na drugim miejscu jest metoda SOR, a na ostatnim metoda Jacobiego (dwie ostatnie czasem zamieniają się miejscami, ale Gauss-Seidel zawsze wygrywa). Zaskakujący jest fakt, że metoda SOR, będąca usprawnieniem metody Gaussa-Seidela daje gorsze rezultaty niż metoda Gaussa-Seidela. Możliwe że parametr $\\omega$ został źle dobrany, ale metodami prób i błędów w przedziale (0,2) nie udało mi się znaleźć takiej wartości, która pozwalałaby uczynić metodę SOR lepszą od metody Gaussa-Seidela"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "C++14",
   "language": "C++14",
   "name": "xeus-cling-cpp14"
  },
  "language_info": {
   "codemirror_mode": "text/x-c++src",
   "file_extension": ".cpp",
   "mimetype": "text/x-c++src",
   "name": "c++",
   "version": "-std=c++14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
